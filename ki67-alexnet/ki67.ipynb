{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "from sklearn import metrics\n",
    "from scipy import interp\n",
    "import os\n",
    "import shutil\n",
    "from keras import backend as K\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "#f = r'E://box3/G/resized/128/train/G3'\n",
    "\n",
    "#os.listdir(f)\n",
    "\n",
    "#for file in os.listdir(f):\n",
    "#    f_img = f+\"/\"+file\n",
    "#    img = Image.open(f_img)\n",
    "#    img = img.resize((80,64))\n",
    "#    img.save(f_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'KI-67/train'\n",
    "#validation_data_dir = '../input/main-dataset/main_dataset/validation'\n",
    "test_data_dir = 'KI-67/test'\n",
    "nb_train_samples = 120\n",
    "nb_validation_samples = 40\n",
    "epochs = 190\n",
    "batch_size = 40\n",
    "#regularizer = tf.keras.regularizers.l2(0.01,)\n",
    "\n",
    "#if K.image_data_format() == 'channels_first':\n",
    "#  input_shape = (3, img_width, img_height)\n",
    "#else:\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale = 1./255,\n",
    "    #shear_range = 0.3,\n",
    "    #zoom_range = 0.2,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(#rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    #classes=['EOISINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL'],\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = 40,\n",
    "    #color_mode = 'grayscale',\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=None, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows +1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eoisinophil=8[1.0.0.0],Lymphocyte=4[0.1.0.0],monocyte=2[0.0.1.0],neutrophil=1[0.0.0.1]-->Labels\n",
    "#plots(imgs, rows=4, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(32, kernel_size=(11,11), strides= 4,\n",
    "#                        padding= 'valid', activation= 'relu',\n",
    "#                        input_shape= input_shape,\n",
    "#                        kernel_initializer= 'he_normal'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "#                              padding= 'valid', data_format= None))\n",
    "\n",
    "#model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "#                        padding= 'same', activation= 'relu',\n",
    "#                        kernel_initializer= 'he_normal'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "#                              padding= 'valid', data_format= None)) \n",
    "\n",
    "#model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "#                        padding= 'same', activation= 'relu',\n",
    "#                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "#model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "#                        padding= 'same', activation= 'relu',\n",
    "#                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "#model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "#                        padding= 'same', activation= 'relu',\n",
    "#                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "#                              padding= 'valid', data_format= None))\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(4096, activation= 'relu'))\n",
    "#model.add(Dense(4096, activation= 'relu'))\n",
    "#model.add(Dense(1000, activation= 'relu'))\n",
    "#model.add(Dense(4, activation= 'softmax'))\n",
    "\n",
    "#model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "#                    loss='categorical_crossentropy',\n",
    "#                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(filters=64, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150,150,3)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "#model.add(Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "#model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "#model.add(Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(4096, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(4096, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "#model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "#                    loss='categorical_crossentropy',\n",
    "#                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 148, 148, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 146, 146, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 146, 146, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 144, 144, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 144, 144, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 71, 71, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 71, 71, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 71, 71, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 71, 71, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 71, 71, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 35, 35, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 35, 35, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 35, 35, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 35, 35, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 35, 35, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 17, 17, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 17, 17, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36992)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              151523328 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,204,098\n",
      "Trainable params: 169,202,178\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),activation='relu', input_shape=(150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())         \n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\terraform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/190\n",
      "2/2 [==============================] - 203s 131s/step - loss: 12.5129 - accuracy: 0.5250 - val_loss: 453.2216 - val_accuracy: 0.5000\n",
      "Epoch 2/190\n",
      "2/2 [==============================] - 67s 41s/step - loss: 51.0888 - accuracy: 0.5625 - val_loss: 230.8513 - val_accuracy: 0.5000\n",
      "Epoch 3/190\n",
      "2/2 [==============================] - 47s 27s/step - loss: 50.2515 - accuracy: 0.4750 - val_loss: 332.7776 - val_accuracy: 0.5000\n",
      "Epoch 4/190\n",
      "2/2 [==============================] - 42s 31s/step - loss: 14.4735 - accuracy: 0.5500 - val_loss: 705.3384 - val_accuracy: 0.5000\n",
      "Epoch 5/190\n",
      "2/2 [==============================] - 35s 22s/step - loss: 13.1745 - accuracy: 0.6625 - val_loss: 622.3927 - val_accuracy: 0.5000\n",
      "Epoch 6/190\n",
      "2/2 [==============================] - 30s 16s/step - loss: 7.0522 - accuracy: 0.5625 - val_loss: 352.8474 - val_accuracy: 0.5000\n",
      "Epoch 7/190\n",
      "2/2 [==============================] - 28s 16s/step - loss: 3.3148 - accuracy: 0.7250 - val_loss: 528.2713 - val_accuracy: 0.5000\n",
      "Epoch 8/190\n",
      "2/2 [==============================] - 30s 17s/step - loss: 8.9470 - accuracy: 0.7000 - val_loss: 1878.4617 - val_accuracy: 0.5000\n",
      "Epoch 9/190\n",
      "2/2 [==============================] - 38s 22s/step - loss: 4.6856 - accuracy: 0.7625 - val_loss: 3379.5962 - val_accuracy: 0.5000\n",
      "Epoch 10/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 3.6233 - accuracy: 0.7375 - val_loss: 2471.9155 - val_accuracy: 0.5000\n",
      "Epoch 11/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 2.0959 - accuracy: 0.8000 - val_loss: 1411.2275 - val_accuracy: 0.5000\n",
      "Epoch 12/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 2.3845 - accuracy: 0.7250 - val_loss: 2376.9277 - val_accuracy: 0.5000\n",
      "Epoch 13/190\n",
      "2/2 [==============================] - 29s 15s/step - loss: 2.4246 - accuracy: 0.8125 - val_loss: 761.4728 - val_accuracy: 0.5000\n",
      "Epoch 14/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 3.3076 - accuracy: 0.7750 - val_loss: 3456.8157 - val_accuracy: 0.5000\n",
      "Epoch 15/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 1.6435 - accuracy: 0.8000 - val_loss: 6032.2422 - val_accuracy: 0.5000\n",
      "Epoch 16/190\n",
      "2/2 [==============================] - 30s 17s/step - loss: 5.6583 - accuracy: 0.8000 - val_loss: 6268.4443 - val_accuracy: 0.5000\n",
      "Epoch 17/190\n",
      "2/2 [==============================] - 30s 16s/step - loss: 4.0205 - accuracy: 0.8000 - val_loss: 4117.4526 - val_accuracy: 0.5000\n",
      "Epoch 18/190\n",
      "2/2 [==============================] - 28s 16s/step - loss: 1.6682 - accuracy: 0.8625 - val_loss: 2594.1553 - val_accuracy: 0.5000\n",
      "Epoch 19/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 1.2150 - accuracy: 0.8500 - val_loss: 3593.6562 - val_accuracy: 0.5000\n",
      "Epoch 20/190\n",
      "2/2 [==============================] - 52s 38s/step - loss: 1.3763 - accuracy: 0.8250 - val_loss: 5214.8232 - val_accuracy: 0.5000\n",
      "Epoch 21/190\n",
      "2/2 [==============================] - 51s 33s/step - loss: 1.0645 - accuracy: 0.8125 - val_loss: 6304.0054 - val_accuracy: 0.5000\n",
      "Epoch 22/190\n",
      "2/2 [==============================] - 34s 20s/step - loss: 0.9440 - accuracy: 0.8375 - val_loss: 6980.3735 - val_accuracy: 0.5000\n",
      "Epoch 23/190\n",
      "2/2 [==============================] - 32s 18s/step - loss: 2.7964 - accuracy: 0.8250 - val_loss: 4643.9131 - val_accuracy: 0.5000\n",
      "Epoch 24/190\n",
      "2/2 [==============================] - 44s 27s/step - loss: 1.6628 - accuracy: 0.8375 - val_loss: 3870.8496 - val_accuracy: 0.5000\n",
      "Epoch 25/190\n",
      "2/2 [==============================] - 41s 25s/step - loss: 2.0044 - accuracy: 0.8125 - val_loss: 3418.1882 - val_accuracy: 0.5000\n",
      "Epoch 26/190\n",
      "2/2 [==============================] - 29s 16s/step - loss: 2.6510 - accuracy: 0.7000 - val_loss: 2633.6458 - val_accuracy: 0.5000\n",
      "Epoch 27/190\n",
      "2/2 [==============================] - 45s 32s/step - loss: 2.3747 - accuracy: 0.7875 - val_loss: 1748.4434 - val_accuracy: 0.5000\n",
      "Epoch 28/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.7137 - accuracy: 0.8625 - val_loss: 1297.1860 - val_accuracy: 0.5000\n",
      "Epoch 29/190\n",
      "2/2 [==============================] - 27s 14s/step - loss: 2.3518 - accuracy: 0.8750 - val_loss: 1740.4348 - val_accuracy: 0.5000\n",
      "Epoch 30/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 1.3367 - accuracy: 0.8250 - val_loss: 2445.1526 - val_accuracy: 0.5000\n",
      "Epoch 31/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 0.8568 - accuracy: 0.8750 - val_loss: 2802.5396 - val_accuracy: 0.5000\n",
      "Epoch 32/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 4.0364 - accuracy: 0.8125 - val_loss: 2439.3950 - val_accuracy: 0.5000\n",
      "Epoch 33/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.2231 - accuracy: 0.9125 - val_loss: 961.2660 - val_accuracy: 0.5000\n",
      "Epoch 34/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 2.2222 - accuracy: 0.8625 - val_loss: 170.2142 - val_accuracy: 0.5000\n",
      "Epoch 35/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 3.2167 - accuracy: 0.8375 - val_loss: 1372.8500 - val_accuracy: 0.5000\n",
      "Epoch 36/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.3166 - accuracy: 0.8625 - val_loss: 2105.8169 - val_accuracy: 0.5000\n",
      "Epoch 37/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 2.1996 - accuracy: 0.9000 - val_loss: 2439.8093 - val_accuracy: 0.5000\n",
      "Epoch 38/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.8657 - accuracy: 0.8375 - val_loss: 2737.2776 - val_accuracy: 0.5000\n",
      "Epoch 39/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 4.5966 - accuracy: 0.8625 - val_loss: 2724.8149 - val_accuracy: 0.5000\n",
      "Epoch 40/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.2271 - accuracy: 0.8625 - val_loss: 2290.5286 - val_accuracy: 0.5000\n",
      "Epoch 41/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.5190 - accuracy: 0.8875 - val_loss: 2122.3191 - val_accuracy: 0.5000\n",
      "Epoch 42/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.4582 - accuracy: 0.9000 - val_loss: 1971.4832 - val_accuracy: 0.5000\n",
      "Epoch 43/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3433 - accuracy: 0.9500 - val_loss: 1837.8445 - val_accuracy: 0.5000\n",
      "Epoch 44/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.1294 - accuracy: 0.7875 - val_loss: 1880.8838 - val_accuracy: 0.5000\n",
      "Epoch 45/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.3997 - accuracy: 0.8625 - val_loss: 1890.1992 - val_accuracy: 0.5000\n",
      "Epoch 46/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 3.0630 - accuracy: 0.8375 - val_loss: 1443.5697 - val_accuracy: 0.5000\n",
      "Epoch 47/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.8105 - accuracy: 0.8875 - val_loss: 648.0742 - val_accuracy: 0.5000\n",
      "Epoch 48/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.6003 - accuracy: 0.8500 - val_loss: 171.9326 - val_accuracy: 0.4000\n",
      "Epoch 49/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.8110 - accuracy: 0.8000 - val_loss: 53.0642 - val_accuracy: 0.4500\n",
      "Epoch 50/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 2.2099 - accuracy: 0.9125 - val_loss: 25.7704 - val_accuracy: 0.4750\n",
      "Epoch 51/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2329 - accuracy: 0.9375 - val_loss: 12.4194 - val_accuracy: 0.4750\n",
      "Epoch 52/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.5211 - accuracy: 0.8875 - val_loss: 7.6776 - val_accuracy: 0.5000\n",
      "Epoch 53/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 0.2997 - accuracy: 0.9250 - val_loss: 17.4714 - val_accuracy: 0.5000\n",
      "Epoch 54/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.5851 - accuracy: 0.8375 - val_loss: 77.4086 - val_accuracy: 0.5500\n",
      "Epoch 55/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3368 - accuracy: 0.8875 - val_loss: 172.5364 - val_accuracy: 0.4750\n",
      "Epoch 56/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1018 - accuracy: 0.9375 - val_loss: 270.9640 - val_accuracy: 0.4750\n",
      "Epoch 57/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.4008 - accuracy: 0.8750 - val_loss: 330.0175 - val_accuracy: 0.4500\n",
      "Epoch 58/190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 27s 15s/step - loss: 0.4377 - accuracy: 0.8875 - val_loss: 339.5789 - val_accuracy: 0.4500\n",
      "Epoch 59/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.1849 - accuracy: 0.9625 - val_loss: 332.9883 - val_accuracy: 0.4750\n",
      "Epoch 60/190\n",
      "2/2 [==============================] - 56s 43s/step - loss: 0.2619 - accuracy: 0.9375 - val_loss: 317.3152 - val_accuracy: 0.4750\n",
      "Epoch 61/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.2140 - accuracy: 0.9125 - val_loss: 321.5922 - val_accuracy: 0.5000\n",
      "Epoch 62/190\n",
      "2/2 [==============================] - 26s 14s/step - loss: 0.1476 - accuracy: 0.9375 - val_loss: 253.4821 - val_accuracy: 0.5250\n",
      "Epoch 63/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1934 - accuracy: 0.9625 - val_loss: 193.0288 - val_accuracy: 0.4750\n",
      "Epoch 64/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.4236 - accuracy: 0.9125 - val_loss: 143.3937 - val_accuracy: 0.4750\n",
      "Epoch 65/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1179 - accuracy: 0.9750 - val_loss: 112.3177 - val_accuracy: 0.5250\n",
      "Epoch 66/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2956 - accuracy: 0.8750 - val_loss: 86.6446 - val_accuracy: 0.5250\n",
      "Epoch 67/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.4530 - accuracy: 0.9500 - val_loss: 41.2840 - val_accuracy: 0.5750\n",
      "Epoch 68/190\n",
      "2/2 [==============================] - 35s 22s/step - loss: 0.0611 - accuracy: 0.9750 - val_loss: 21.5227 - val_accuracy: 0.6000\n",
      "Epoch 69/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.4466 - accuracy: 0.9625 - val_loss: 15.2957 - val_accuracy: 0.6250\n",
      "Epoch 70/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1104 - accuracy: 0.9625 - val_loss: 13.5139 - val_accuracy: 0.6500\n",
      "Epoch 71/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 12.9903 - val_accuracy: 0.6750\n",
      "Epoch 72/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.3894 - accuracy: 0.9500 - val_loss: 12.7121 - val_accuracy: 0.6250\n",
      "Epoch 73/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 11.9377 - val_accuracy: 0.6250\n",
      "Epoch 74/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3937 - accuracy: 0.9250 - val_loss: 9.5736 - val_accuracy: 0.6250\n",
      "Epoch 75/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.2377 - accuracy: 0.9375 - val_loss: 8.3283 - val_accuracy: 0.6000\n",
      "Epoch 76/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2422 - accuracy: 0.9500 - val_loss: 10.3119 - val_accuracy: 0.5500\n",
      "Epoch 77/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0599 - accuracy: 0.9750 - val_loss: 16.7537 - val_accuracy: 0.5000\n",
      "Epoch 78/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0735 - accuracy: 0.9875 - val_loss: 24.2888 - val_accuracy: 0.4500\n",
      "Epoch 79/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1239 - accuracy: 0.9750 - val_loss: 32.6665 - val_accuracy: 0.4500\n",
      "Epoch 80/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1896 - accuracy: 0.9500 - val_loss: 37.2392 - val_accuracy: 0.4500\n",
      "Epoch 81/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1535 - accuracy: 0.9750 - val_loss: 40.8684 - val_accuracy: 0.5000\n",
      "Epoch 82/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.4967 - accuracy: 0.9125 - val_loss: 42.4889 - val_accuracy: 0.4750\n",
      "Epoch 83/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0145 - accuracy: 0.9875 - val_loss: 44.4875 - val_accuracy: 0.4500\n",
      "Epoch 84/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.2475 - accuracy: 0.9375 - val_loss: 39.7786 - val_accuracy: 0.4750\n",
      "Epoch 85/190\n",
      "2/2 [==============================] - 66s 54s/step - loss: 0.2291 - accuracy: 0.9500 - val_loss: 33.1469 - val_accuracy: 0.5500\n",
      "Epoch 86/190\n",
      "2/2 [==============================] - 44s 26s/step - loss: 0.0230 - accuracy: 0.9875 - val_loss: 28.0053 - val_accuracy: 0.6250\n",
      "Epoch 87/190\n",
      "2/2 [==============================] - 41s 26s/step - loss: 0.1253 - accuracy: 0.9625 - val_loss: 26.6545 - val_accuracy: 0.6500\n",
      "Epoch 88/190\n",
      "2/2 [==============================] - 39s 27s/step - loss: 0.0453 - accuracy: 0.9625 - val_loss: 25.6942 - val_accuracy: 0.7000\n",
      "Epoch 89/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0127 - accuracy: 0.9875 - val_loss: 25.4261 - val_accuracy: 0.6500\n",
      "Epoch 90/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0467 - accuracy: 0.9750 - val_loss: 24.5044 - val_accuracy: 0.6250\n",
      "Epoch 91/190\n",
      "2/2 [==============================] - 44s 32s/step - loss: 0.0587 - accuracy: 0.9875 - val_loss: 22.5653 - val_accuracy: 0.6250\n",
      "Epoch 92/190\n",
      "2/2 [==============================] - 53s 36s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 20.2353 - val_accuracy: 0.6250\n",
      "Epoch 93/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0556 - accuracy: 0.9750 - val_loss: 17.6937 - val_accuracy: 0.6500\n",
      "Epoch 94/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0583 - accuracy: 0.9875 - val_loss: 16.0870 - val_accuracy: 0.6500\n",
      "Epoch 95/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0268 - accuracy: 0.9875 - val_loss: 16.1570 - val_accuracy: 0.6750\n",
      "Epoch 96/190\n",
      "2/2 [==============================] - 28s 16s/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 16.8288 - val_accuracy: 0.7250\n",
      "Epoch 97/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3727 - accuracy: 0.9750 - val_loss: 20.8698 - val_accuracy: 0.7000\n",
      "Epoch 98/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 24.5222 - val_accuracy: 0.6750\n",
      "Epoch 99/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0603 - accuracy: 0.9875 - val_loss: 27.4893 - val_accuracy: 0.6750\n",
      "Epoch 100/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3638 - accuracy: 0.9250 - val_loss: 29.2904 - val_accuracy: 0.6500\n",
      "Epoch 101/190\n",
      "2/2 [==============================] - 32s 19s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 31.3422 - val_accuracy: 0.6500\n",
      "Epoch 102/190\n",
      "2/2 [==============================] - 36s 24s/step - loss: 0.0330 - accuracy: 0.9750 - val_loss: 32.1418 - val_accuracy: 0.6500\n",
      "Epoch 103/190\n",
      "2/2 [==============================] - 34s 20s/step - loss: 0.2140 - accuracy: 0.9750 - val_loss: 24.5129 - val_accuracy: 0.6750\n",
      "Epoch 104/190\n",
      "2/2 [==============================] - 46s 32s/step - loss: 0.0346 - accuracy: 0.9750 - val_loss: 17.7451 - val_accuracy: 0.6500\n",
      "Epoch 105/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0404 - accuracy: 0.9750 - val_loss: 14.0960 - val_accuracy: 0.7000\n",
      "Epoch 106/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0643 - accuracy: 0.9625 - val_loss: 11.9348 - val_accuracy: 0.7000\n",
      "Epoch 107/190\n",
      "2/2 [==============================] - 28s 16s/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 11.2105 - val_accuracy: 0.7000\n",
      "Epoch 108/190\n",
      "2/2 [==============================] - 35s 22s/step - loss: 0.2718 - accuracy: 0.9750 - val_loss: 11.7217 - val_accuracy: 0.7250\n",
      "Epoch 109/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 12.5882 - val_accuracy: 0.7000\n",
      "Epoch 110/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 13.2645 - val_accuracy: 0.6750\n",
      "Epoch 111/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 13.8164 - val_accuracy: 0.6750\n",
      "Epoch 112/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 14.3126 - val_accuracy: 0.7000\n",
      "Epoch 113/190\n",
      "2/2 [==============================] - 38s 26s/step - loss: 0.0880 - accuracy: 0.9625 - val_loss: 14.9348 - val_accuracy: 0.7250\n",
      "Epoch 114/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 15.0244 - val_accuracy: 0.7250\n",
      "Epoch 115/190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 27s 15s/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 15.6886 - val_accuracy: 0.7000\n",
      "Epoch 116/190\n",
      "2/2 [==============================] - 37s 24s/step - loss: 0.0127 - accuracy: 0.9875 - val_loss: 16.7742 - val_accuracy: 0.7000\n",
      "Epoch 117/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1823 - accuracy: 0.9750 - val_loss: 13.2689 - val_accuracy: 0.7250\n",
      "Epoch 118/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 1.2972e-04 - accuracy: 1.0000 - val_loss: 12.3291 - val_accuracy: 0.6750\n",
      "Epoch 119/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 12.7057 - val_accuracy: 0.6750\n",
      "Epoch 120/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 13.1690 - val_accuracy: 0.7000\n",
      "Epoch 121/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0811 - accuracy: 0.9750 - val_loss: 13.4645 - val_accuracy: 0.7000\n",
      "Epoch 122/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0490 - accuracy: 0.9750 - val_loss: 13.5671 - val_accuracy: 0.7000\n",
      "Epoch 123/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 13.4814 - val_accuracy: 0.6750\n",
      "Epoch 124/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 13.2999 - val_accuracy: 0.6750\n",
      "Epoch 125/190\n",
      "2/2 [==============================] - 28s 16s/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 12.3598 - val_accuracy: 0.6750\n",
      "Epoch 126/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 10.9893 - val_accuracy: 0.6750\n",
      "Epoch 127/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 9.6449 - val_accuracy: 0.6500\n",
      "Epoch 128/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 8.6777 - val_accuracy: 0.7000\n",
      "Epoch 129/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 4.2645e-06 - accuracy: 1.0000 - val_loss: 8.0538 - val_accuracy: 0.7250\n",
      "Epoch 130/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 6.0845e-04 - accuracy: 1.0000 - val_loss: 7.7021 - val_accuracy: 0.7500\n",
      "Epoch 131/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0525 - accuracy: 0.9750 - val_loss: 7.6153 - val_accuracy: 0.7250\n",
      "Epoch 132/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 5.5664e-04 - accuracy: 1.0000 - val_loss: 7.6309 - val_accuracy: 0.7000\n",
      "Epoch 133/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0581 - accuracy: 0.9875 - val_loss: 5.1476 - val_accuracy: 0.6750\n",
      "Epoch 134/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.1089 - val_accuracy: 0.6500\n",
      "Epoch 135/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3429 - accuracy: 0.9625 - val_loss: 2.8071 - val_accuracy: 0.6250\n",
      "Epoch 136/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.6915 - val_accuracy: 0.5500\n",
      "Epoch 137/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0117 - accuracy: 0.9875 - val_loss: 9.3042 - val_accuracy: 0.5500\n",
      "Epoch 138/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 1.1964 - accuracy: 0.9125 - val_loss: 4.6493 - val_accuracy: 0.6250\n",
      "Epoch 139/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0104 - accuracy: 0.9875 - val_loss: 15.0777 - val_accuracy: 0.5750\n",
      "Epoch 140/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.9373 - accuracy: 0.9500 - val_loss: 25.5683 - val_accuracy: 0.5750\n",
      "Epoch 141/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1728 - accuracy: 0.9750 - val_loss: 32.4591 - val_accuracy: 0.5750\n",
      "Epoch 142/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 36.0236 - val_accuracy: 0.5750\n",
      "Epoch 143/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1111 - accuracy: 0.9750 - val_loss: 23.6918 - val_accuracy: 0.6250\n",
      "Epoch 144/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.8596 - accuracy: 0.9375 - val_loss: 14.1896 - val_accuracy: 0.6750\n",
      "Epoch 145/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1991 - accuracy: 0.9500 - val_loss: 7.8767 - val_accuracy: 0.6500\n",
      "Epoch 146/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2912 - accuracy: 0.9875 - val_loss: 4.2087 - val_accuracy: 0.6500\n",
      "Epoch 147/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2293 - accuracy: 0.9625 - val_loss: 3.5966 - val_accuracy: 0.6250\n",
      "Epoch 148/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0465 - accuracy: 0.9750 - val_loss: 4.4310 - val_accuracy: 0.6000\n",
      "Epoch 149/190\n",
      "2/2 [==============================] - 44s 32s/step - loss: 0.3955 - accuracy: 0.9750 - val_loss: 5.1867 - val_accuracy: 0.6000\n",
      "Epoch 150/190\n",
      "2/2 [==============================] - 41s 29s/step - loss: 0.2732 - accuracy: 0.9625 - val_loss: 4.6551 - val_accuracy: 0.6000\n",
      "Epoch 151/190\n",
      "2/2 [==============================] - 36s 24s/step - loss: 0.1534 - accuracy: 0.9625 - val_loss: 4.9605 - val_accuracy: 0.5750\n",
      "Epoch 152/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3047 - accuracy: 0.9250 - val_loss: 5.1410 - val_accuracy: 0.6500\n",
      "Epoch 153/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.3686 - accuracy: 0.9750 - val_loss: 3.7391 - val_accuracy: 0.6750\n",
      "Epoch 154/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.7759 - val_accuracy: 0.7250\n",
      "Epoch 155/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.2204 - accuracy: 0.9500 - val_loss: 4.5046 - val_accuracy: 0.7250\n",
      "Epoch 156/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.0886 - accuracy: 0.9750 - val_loss: 5.8014 - val_accuracy: 0.6500\n",
      "Epoch 157/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.1201 - accuracy: 0.9500 - val_loss: 5.1168 - val_accuracy: 0.6500\n",
      "Epoch 158/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 4.5663 - val_accuracy: 0.6000\n",
      "Epoch 159/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.0894 - accuracy: 0.9875 - val_loss: 4.5109 - val_accuracy: 0.5750\n",
      "Epoch 160/190\n",
      "2/2 [==============================] - 28s 15s/step - loss: 0.1419 - accuracy: 0.9625 - val_loss: 5.1301 - val_accuracy: 0.5750\n",
      "Epoch 161/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.5155 - accuracy: 0.9000 - val_loss: 6.9640 - val_accuracy: 0.5500\n",
      "Epoch 162/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.4097 - val_accuracy: 0.5500\n",
      "Epoch 163/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.4092 - accuracy: 0.9500 - val_loss: 9.6446 - val_accuracy: 0.5750\n",
      "Epoch 164/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.2246 - accuracy: 0.9625 - val_loss: 9.8619 - val_accuracy: 0.6250\n",
      "Epoch 165/190\n",
      "2/2 [==============================] - 26s 15s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 9.6551 - val_accuracy: 0.6250\n",
      "Epoch 166/190\n",
      "2/2 [==============================] - 27s 15s/step - loss: 0.1248 - accuracy: 0.9750 - val_loss: 9.3990 - val_accuracy: 0.6500\n",
      "Epoch 167/190\n",
      "2/2 [==============================] - 31s 18s/step - loss: 0.0472 - accuracy: 0.9750 - val_loss: 9.4234 - val_accuracy: 0.6500\n",
      "Epoch 168/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0484 - accuracy: 0.9875 - val_loss: 9.5832 - val_accuracy: 0.6500\n",
      "Epoch 169/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0292 - accuracy: 0.9875 - val_loss: 9.1401 - val_accuracy: 0.6750\n",
      "Epoch 170/190\n",
      "2/2 [==============================] - 32s 17s/step - loss: 0.0742 - accuracy: 0.9750 - val_loss: 7.7134 - val_accuracy: 0.6000\n",
      "Epoch 171/190\n",
      "2/2 [==============================] - 32s 17s/step - loss: 0.0991 - accuracy: 0.9875 - val_loss: 7.4383 - val_accuracy: 0.5250\n",
      "Epoch 172/190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 31s 17s/step - loss: 0.1807 - accuracy: 0.9875 - val_loss: 7.2740 - val_accuracy: 0.5500\n",
      "Epoch 173/190\n",
      "2/2 [==============================] - 33s 18s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.1009 - val_accuracy: 0.5000\n",
      "Epoch 174/190\n",
      "2/2 [==============================] - 33s 19s/step - loss: 0.1064 - accuracy: 0.9750 - val_loss: 6.6257 - val_accuracy: 0.5500\n",
      "Epoch 175/190\n",
      "2/2 [==============================] - 33s 18s/step - loss: 0.1459 - accuracy: 0.9875 - val_loss: 6.1801 - val_accuracy: 0.5250\n",
      "Epoch 176/190\n",
      "2/2 [==============================] - 33s 18s/step - loss: 0.1638 - accuracy: 0.9750 - val_loss: 6.6026 - val_accuracy: 0.5250\n",
      "Epoch 177/190\n",
      "2/2 [==============================] - 32s 17s/step - loss: 0.3319 - accuracy: 0.9500 - val_loss: 7.5948 - val_accuracy: 0.5750\n",
      "Epoch 178/190\n",
      "2/2 [==============================] - 32s 18s/step - loss: 0.1358 - accuracy: 0.9875 - val_loss: 8.2555 - val_accuracy: 0.5750\n",
      "Epoch 179/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0163 - accuracy: 0.9875 - val_loss: 8.7654 - val_accuracy: 0.5500\n",
      "Epoch 180/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 8.8775 - val_accuracy: 0.5250\n",
      "Epoch 181/190\n",
      "2/2 [==============================] - 32s 18s/step - loss: 0.0635 - accuracy: 0.9750 - val_loss: 7.6830 - val_accuracy: 0.5000\n",
      "Epoch 182/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0450 - accuracy: 0.9625 - val_loss: 6.7733 - val_accuracy: 0.5750\n",
      "Epoch 183/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.1856 - accuracy: 0.9750 - val_loss: 6.8908 - val_accuracy: 0.5250\n",
      "Epoch 184/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 7.3464 - val_accuracy: 0.5250\n",
      "Epoch 185/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0856 - accuracy: 0.9875 - val_loss: 7.6927 - val_accuracy: 0.5000\n",
      "Epoch 186/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 8.2036 - val_accuracy: 0.5250\n",
      "Epoch 187/190\n",
      "2/2 [==============================] - 31s 17s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 8.3521 - val_accuracy: 0.5000\n",
      "Epoch 188/190\n",
      "2/2 [==============================] - 32s 18s/step - loss: 0.1265 - accuracy: 0.9750 - val_loss: 7.8721 - val_accuracy: 0.5000\n",
      "Epoch 189/190\n",
      "2/2 [==============================] - 32s 17s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 7.7807 - val_accuracy: 0.5250\n",
      "Epoch 190/190\n",
      "2/2 [==============================] - ETA: 0s - loss: 6.4075e-08 - accuracy: 1.0000 "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = model.fit_generator(\n",
    "    train_batches,\n",
    "    steps_per_epoch = 2,\n",
    "    epochs = epochs,\n",
    "    validation_data = test_batches,\n",
    "    validation_steps = nb_validation_samples // batch_size,\n",
    "    #callbacks=[\n",
    "    #    tf.keras.callbacks.ModelCheckpoint(filepath = '/kaggle/working/model_{val_accuracy:.3f}.h5', save_best_only=True,\n",
    "    #                                      save_weights_only=False, monitor='val_accuracy')\n",
    "    #]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "#plots(test_imgs, rows=10, titles=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_labels = np.argmax(test_labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_0.92015612.h5')\n",
    "test_model = load_model('model_0.92015612.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_model.predict_generator(test_batches, steps=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prediction = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rounded_prediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=rounded_labels, y_pred=rounded_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_plot_labels = ['A','B']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_labels.ravel(), predictions.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(2)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(2):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 2\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(2), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(2), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=rounded_labels, y_pred=rounded_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metrics.log_loss(test_labels,predictions)\n",
    "print(\"Log loss score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = h.history['accuracy']\n",
    "val_accs = h.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_accuracy')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = h.history['loss']\n",
    "val_accs = h.history['val_loss']\n",
    "\n",
    "plt.plot(range(len(accs)),accs, label = 'Training_loss')\n",
    "plt.plot(range(len(accs)),val_accs, label = 'Validation_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
